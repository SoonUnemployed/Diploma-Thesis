{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7aecd81",
   "metadata": {},
   "source": [
    "Automatic preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import os\n",
    "import import_ipynb \n",
    "import /Users/hrakol/Documens/GitHub/Create_database\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb98f29",
   "metadata": {},
   "source": [
    "Add parameters to pass file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c39fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only bdf files\n",
    "files =[f for f in os.listdir(\"/Users/hrakol/Desktop/Thesis EEG\") if f.endswith(\".bdf\")]\n",
    "\n",
    "for filename in files:\n",
    "    filename = filename[:-4]\n",
    "    #Do the preprocessing for each file\n",
    "    pm.execute_notebook(\n",
    "        #input notebook\n",
    "        f\"/Users/hrakol/Desktop/Thesis EEG/Real_Time_Pre.ipynb\",\n",
    "        #output notebook\n",
    "        f\"/Users/hrakol/Desktop/Thesis EEG/output_{filename}.ipynb\",\n",
    "        #parameters\n",
    "        parameters = {\"filename\": filename}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/hrakol/Desktop/Thesis EEG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77efe7a",
   "metadata": {},
   "source": [
    "Use all the needed functions from Create_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = get_files(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_per_user, each_freq_av = get_averages(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1, stimuli_1, user_ids_1 = make_lists(all_data, 1)\n",
    "features_2, stimuli_2, user_ids_2 = make_lists(all_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1, x_2, y_1, y_2, loader_1, loader_2 = make_databases(features_1, features_2, user_ids_1, user_ids_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = UserClassifier(x_1.shape[1], len(torch.unique(y_1)))\n",
    "model2 = UserClassifier(x_2.shape[1], len(torch.unique(y_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the stimuli labels to each feature with OneHotEncoder\n",
    "stimuli_1 = np.hstack(stimuli_1)\n",
    "stimuli_2 = np.hstack(stimuli_2)\n",
    "\n",
    "stimuli_1 = stimuli_1.reshape(-1,1)\n",
    "stimuli_2 = stimuli_2.reshape(-1,1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output = False)\n",
    "stimuli_1 = encoder.fit_transform(stimuli_1)\n",
    "stimuli_2 = encoder.fit_transform(stimuli_2)\n",
    "\n",
    "#Add the encoded stimuli labels to the corresponding feature\n",
    "features_1 = np.hstack([features_1, stimuli_1])\n",
    "features_2 = np.hstack([features_2, stimuli_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1, x_2, y_1, y_2, loader_1, loader_2 = make_databases(features_1, features_2, user_ids_1, user_ids_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33627fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = EEGUserClassifier(x_1.shape[1], len(torch.unique(y_1)))\n",
    "model4 = EEGUserClassifier(x_2.shape[1], len(torch.unique(y_2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
